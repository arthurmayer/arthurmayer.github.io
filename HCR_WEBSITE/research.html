<!DOCTYPE html>
<html>
<head>
  <title>Human-Centered Robotics Lab @ Mines</title>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css">
  <link rel="stylesheet" href="css/style.css">
  <link rel="icon" href="images/csm.jpg">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js"></script>
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js"></script>
</head>
<body>
  <header>
    <div id="logo">
      <div id="logo_text">
        <h1><a href="index.html"><strong>Human-Centered Robotics Lab</strong></a></h1>
        <h4>Lifelong collaborative autonomy, robot adaptation, multisensory perception, and human-robot/swarm teaming</h2>
      </div>
    </div>
    <nav class="navbar navbar-expand-sm navbar-light sticky-top">
      <ul class="navbar-nav">
        <li class="nav-item"><a class="nav-link" href="index.html">Home</a></li>
        <li class="nav-item"><a class="nav-link" href="people.html">People</a></li>
        <li class="nav-item active"><a class="nav-link" href="research.html">Research</a></li>
        <li class="nav-item"><a class="nav-link" href="outreach.html">Outreach</a></li>
        <li class="nav-item"><a class="nav-link" href="publications.html">Publications</a></li>
        <li class="nav-item"><a class="nav-link" href="media.html">Media</a></li>
        <li class="nav-item"><a class="nav-link" href="contact.html">Contact</a></li>
      </ul>
    </nav>
  </header>

  <div id="content">
    <p>We focus on innovative theoretical and applied research on <em><strong>lifelong collaborative autonomy</strong></em>,
      in order to enable robots to collaborate with humans, assist people, take over tasks where our current society has shortcomings, and operate over long periods of time
      (e.g., across days, months, years, and eventually over their lifetimes).
      Our research lies at the intersection of robotics, artificial intelligence, machine learning, and augmented and mixed reality,
      with specific research topics focusing on robot adaptation and learning,  multisensory perception, and human-robot/swarm teaming</em> in dynamic, unstructured, open, and potentially adversarial field environments.
      Our research leads to new robotics solutions with solid algorithmic foundations to address environmental, social
      and economic issues, impacting the state of national health, education, safety, productivity, efficiency, and the economy.
    </p>
    <hr/>
    <h2>Sponsors</h2>
    <p>Our research and educational activities are supported by Metcalf Archaeological Consultants, Inc. (Metcalf),
      Army Research Office (ARO), National Science Foundation (NSF), Department of Energy (DOE),
      Department of Transportation (DOT) Pipeline and Hazardous Materials Safety Administration (PHMSA), Army Research Laboratory (ARL), United States Air Force Academy (USAFA),
      Colorado Energy Research Collaboratory (CERC), Toyota Motor North America, and Alpha Foundation.
    </p>
    <!-- TODO: Fix the content so it forms rows appropriately based on screen size -->
    <div class="row">
      <div class="col-1"></div>
      <div class="col-lg-5">
        <div class="row">
          <div class="col-2"></div>
          <div class="col-2"><img class="sponsor" src="images/sponsors/metcalf.png" /></div>
          <div class="col-2"><img class="sponsor" src="images/sponsors/aro.gif" /></div>
          <div class="col-2"><img class="sponsor" src="images/sponsors/nsf.jpg" /></div>
          <div class="col-2"><img class="sponsor" src="images/sponsors/doe.jpg" /></div>
          <div class="col-2"><img class="sponsor" src="images/sponsors/dot.png" /></div>
        </div>
      </div>
      <div class="col-lg-5">
        <div class="row">
          <div class="col-2"><img class="sponsor" src="images/sponsors/arl.png" /></div>
          <div class="col-2"><img class="sponsor" src="images/sponsors/usafa.png" /></div>
          <div class="col-2"><img class="sponsor" src="images/sponsors/cerc.png" /></div>
          <div class="col-2"><img class="sponsor" src="images/sponsors/toyota.png" /></div>
          <div class="col-2"><img class="sponsor" src="images/sponsors/alphafoundation.jpg" /></div>
          <div class="col-2"></div>
        </div>
      </div>
      <div class="col-1"></div>
    </div>

    <hr />

    <h2>Current Projects</h2>
    <h4>Robotic Solutions for Underground Exploration</h4>
    <div class="row">
        <div class="col-md-8">
            <p>The global community is increasingly exploring underground environments for sustainable and resilient solutions to societal problems.
               Communities are moving infrastructure such as roads, data centers, and water treatment facilities below ground.
               Exploration, inspection and rescue operations in underground environments are both unsafe and challenging,
               requiring the use of a number of advanced technologies like robotics and robotic swarms.
               Many challenges must be addressed to design effective robotics solutions for the underground.
               For example, robots must be able to recognize victims and critical objects, localize themselves in similar underground environments,
               navigate autonomously over various terrain, and collaborate under communication constraints.
               <br>
               <em><strong>Sponsors:</strong> NSF</em>
            </p>
        </div>
        <div class="col-md-4"><img src="images/UndergroundRobotics.png" style="width: 100%;" /></div>
    </div>
    <br />

    <h4>Robot-Assisted Reconnaissance, Inspection, and Repair</h4>
    <div class="row">
        <div class="col-md-8">
            <p>Reconnaissance, inspection, and repair in dangerous environment has many real-world applications.
               For example, it is essential to detect treats in power plant boilers or pipeline networks, and track their growth rate over time across multiple inspections,
               as a boiler or pipeline accident can cost millions of dollars for healthcare bills, infrastructure replacement, environmental response, and clean-up operations.
               Many computational challenges are present in such applications, including how robots can recognize objects of interest (e.g., erosions in boilers or pipes),
               how to localize them in multiple runs potentially across a long time span, and how to track and predict their changes over time (e.g., growth rate of erosions).
               <br>
               <em><strong>Sponsors:</strong> DOE and DOT</em>
            </p>
        </div>
        <div class="col-md-4"><img src="images/ProjInspection.png" style="width: 100%;"/></div>
    </div>
    <br />

    <h4>Robot Modelling of People and Teamwork</h4>
    <div class="row">
        <div class="col-md-8">
          <p>We envision that robots and humans team up and work together side-by-side with an interaction style that is not based on direct controls
             and commands from humans to robots, but rather on the idea that robots can implicitly infer human intents and activities through passive observation.
             This would allow a person to collaborate with robots in a natural manner, as he/she would when teaming with human teammates,
             thus bypassing the difficulty of cognitive overload that occurs when humans are required to explicitly supervise robot teammates.
             This direction of research focuses on estimating human states (e.g., activities, emotions, intents, and goals)
             and modeling teamwork from robots' multisensory observations.
             <br>
             <em><strong>Sponsors:</strong> NSF, ARO, USAFA, and CERC</em>
          </p>
        </div>
        <div class="col-md-4"><img src="images/ActivityAwareness.png" style="width: 100%;"/></div>
    </div>
    <br />

    <h4>Distributed Collaboration Localization and Tracking</h4>
    <div class="row">
        <div class="col-md-8">
          <p>Robust and efficient detection and tracking of objects in complex environments
             is critical to ensure safe and effective operations of autonomous agents
             in real-world human-centered environments.
             Our research is focused on developing approaches of collaborative perception from multiple agents to detect, localize,
             and track multiple objects with deformable shapes and significant appearance changes during long periods of time.
             This research supports our applications including human-robot teaming,
             autonomous driving, and augmented reality (AR).
             <br>
             <em><strong>Sponsors:</strong> Metcalf Archaeological Consultants, Inc. and  Toyota InfoTechnology Center</em>
          </p>
        </div>
        <div class="col-md-4"><img src="images/DetectionTracking.png" style="width: 100%;"/></div>
    </div>

    <hr />

    <h2>Code and Datasets</h2>
    <ul>
      <li>(Code) <a class="datasets" href="./code/FABL.html" target="blank"><strong>FABL</strong>:Feature and Body-part Learning</a> to enable real-time robot awareness of human behaviors. Released: 09/2016.</li>
      <li>(Code) <a class="datasets" href="./code/SRAL.html" target="blank"><strong>SRAL</strong>:Shared Representative Appearance Learning</a> for long-term place recognition. Released: 08/2016.</li>
      <li>(Dataset) <a class="datasets" href="" target="blank"><strong>MUTA</strong>: Multisensory Unstructured Terrain Adaptation</a> dataset to facilitate research on robot adaptation to unstructured terrains in field applications.</li>
      <li>(Dataset) <a class="datasets" href="./code/MOLP.html" target="blank"><strong>MOLP</strong>: Multimodal Omni-directional Long-term Place-recognition</a> to facilitate research on long-term multimodal place recognition. Released: 06/2018.</li>
    </ul>
  </div>

  <footer>
    <div id="contact">
      <h4>Contact</h4>
      <hr>
      <div class="row">
        <div class="col-sm-4" style="text-align: center;">
          <img src="images/people/hzhang.jpg" style="width: 50%; margin: 0 auto;">
          <p>
            <a href="http://inside.mines.edu/~hzhang/" target="_blank" style="color: #333399;">Dr. Hao Zhang</a>
          </p>
        </div>
        <div class="col-sm-4" style="text-align: center;">
           <p>
            Dept. of Computer Science <br>
            Colorado School of Mines <br>
            1610 Illinois Street <br>
            Golden, CO 80401
          </p>
        </div>
        <div class="col-sm-4" style="text-align: center;">
          <p>
            Lab: Brown Hall BBW 325 <br>
            Office: Brown Hall 250 <br>
            Email: hzhang@mines.edu <br>
            Phone: (303) 273-3581 <br>
            Fax: (303) 273-3602
          </p>
        </div>
      </div>
    </div>
    <div id="footer-external">
      <p><a href="index.html">HCRobotics Lab</a> | <a href="http://inside.mines.edu/CS-home">Department of Computer Science</a> | <a href="http://mines.edu">Colorado School of Mines</a></p>
    </div>
  </footer>
</body>
</html>